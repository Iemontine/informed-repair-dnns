\documentclass{article}

% Pass options to natbib to use the references.bib file
\PassOptionsToPackage{numbers, compress}{natbib}

% ready for submission
% \usepackage{neurips_2025}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    % \usepackage[preprint]{neurips_2025}

% to compile a camera-ready version, add the [final] option, e.g.:
    \usepackage[final]{neurips_2025}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2025}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\title{Informed Repair of Deep Neural Networks}

\begin{document}

\author{
    Akshat Adsule \\
    University of California, Davis \\
    \texttt{aadsule@ucdavis.edu}
    \And
    Darroll Saddi \\
    University of California, Davis \\
    \texttt{dsaddi@ucdavis.edu}
    \And
    Suyash Goel \\
    University of California, Davis \\
    \texttt{sngoel@ucdavis.edu}
}

\maketitle

% \begin{abstract}
%     Work in Progress
% \end{abstract}

\section{Introduction}

Deep neural networks (DNNs) have become increasingly prevalent in modern applications.
DNNs have seen use in virtually every field from air traffic control to self-driving vehicles.
However, these models are not infallible and do produce mistakes, which could prove disastrous given the model's application.

Recent research \cite{nawas_provable_2024, sotoudeh_provable_2021, tao_architecture-preserving_2023} has explored methods of repairing DNNs once incorrect inputs are identified.
These techniques typically aim to minimally adjust the network's parameters to correct its behavior on the specified repair set, often while providing formal guarantees on the outcome for those inputs or related input regions.
However, applying these repair methods in practice reveals significant ambiguities that can affect the quality and efficiency of the repair.

Take, for example, APRNN, the method proposed in \cite{tao_architecture-preserving_2023} that offers provable, architecture-preserving repair over specified input regions (V-polytopes).
APRNN achieves this guarantee, in part, by ensuring the network behaves linearly within the target region up to a chosen layer.
This involves modifying network weights starting primarily at that chosen layer and adjusting biases in subsequent layers.

While effective, this process introduces critical ambiguities in practice. One such ambiguity comes from selecting the starting layer for weight modifications.
The paper itself doesn't prescribe how to choose this layer, and this choice can significantly impact the repair's effectiveness, efficiency, and efficacy.
Moreover, how a repair set is selected also greatly impacts the quality of repair.
In APRNN, the specific examples included in the repair set, which define the repair polytope, fundamentally determine the target behavior.
The composition and scope of this set influence the repair outcome and how well the fix generalizes to similar, unseen inputs.

This paper aims to investigate and develop heuristics to guide the DNN repair process, specifically addressing the ambiguities highlighted above in methods like APRNN. By providing data-driven or structurally-informed ways to make these choices, we seek to enable more efficient and informed repairs of DNNs.
We propose to explore and evaluate various heuristics, including but not limited to:

% \subsubsection*{Layer Selection Heuristics}
\underline{Layer Selection Heuristics:}
\begin{description}
    \item[Activation-Based] Selecting the start layer based on metrics calculated across the repair set, such as the layer exhibiting the highest average activation magnitude or the highest variance in activations.
    \item[Gradient/Sensitivity-Based] Identifying layers where parameters show the most sensitivity (e.g., largest gradient norms) with respect to the inputs in the repair set, indicating layers most influential on the incorrect output.
    \item[Change-Based (for Adversarial Inputs)] Selecting the layer whose activations or feature representations changed most drastically between the original and adversarial inputs in the repair set.
    \item[Feature-Similarity Based] Choosing a layer where the internal representations of the inputs within the repair set are most similar, suggesting a point of unified processing relevant to the required fix.
    \item[Layer Type/Position] Simple heuristics such as always choosing the first fully-connected layer after convolutional blocks, or the penultimate layer.
\end{description}

\underline{Repair Set Analysis}
\begin{description}
    \item[Diversity] Evaluating the diversity of the repair set, such as the number of unique classes or the distribution of inputs across the input space.
    \item[Concentration] Analyzing the concentration of points defining the polytope, such as the number of points needed to define a convex hull or the dimensionality of the convex hull.
    \item[Size] Considering the size of the repair set, including the number of points and the dimensionality of the input space.
\end{description}

This project enhances AI trustworthiness by making the crucial process of model repair—itself a method for increasing trust after failures—more efficient and informed. Current repair techniques can involve arbitrary choices, leading to unpredictable outcomes. By developing heuristics to guide decisions within the repair process, such as selecting the optimal network layer for modification, we enable more systematic, reliable, and effective correction of identified flaws. This ultimately increases confidence in the robustness and safety of AI systems by ensuring that necessary fixes are applied more predictably and with a better understanding of their potential impact.

% Add bibliography at the end
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}